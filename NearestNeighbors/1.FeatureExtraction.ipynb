{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "Requirements:\n",
    "\n",
    "* [Download NFT Images](https://drive.google.com/file/d/1uo1mXRRkXcrY1u1bkWj_aEsoW6M3L_7o/view?usp=sharing) and Extract them in a folder named `NFTs`\n",
    "\n",
    "Folder structure should be like this:\n",
    "\n",
    "```bash\n",
    "tree NFTs                                               \n",
    "NFTs\n",
    "└── collection\n",
    "    ├── NFT-10005.png\n",
    "    ├── NFT-10007.png\n",
    "    ├── NFT-10009.png\n",
    "    ├── NFT-10010.jpg\n",
    "    ├── NFT-10013.jpg\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root folder for NFT Images\n",
    "nft_images_root_folder = 'NFTs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch import topk\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imagenet Statistics mean/std\n",
    "\n",
    "normalize = transforms.Normalize(\n",
    "   mean=[0.485, 0.456, 0.406],\n",
    "   std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "# Preprocessing - scale to 224x224 for model, convert to tensor, \n",
    "# and normalize to -1..1 with mean/std for ImageNet\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "   transforms.Resize((224, 224)),\n",
    "   transforms.ToTensor(),\n",
    "   normalize\n",
    "])\n",
    "\n",
    "display_transform = transforms.Compose([\n",
    "   transforms.Resize((224, 224))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "concat = lambda x: np.concatenate(x, axis=0)\n",
    "to_np  = lambda x: x.data.to('cpu').numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extractor from ResNet101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Extracor (This is no outdates, PyTorch supports feature extraction via an API)\n",
    "class Lyaer4Extractor(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Lyaer4Extractor, self).__init__()\n",
    "    \n",
    "    self.model = models.resnet101(pretrained=True)\n",
    "    self.model.cuda()\n",
    "    self.model.eval();\n",
    "    \n",
    "    self.a_embeddings = None\n",
    "    \n",
    "    def a_hook(module, input, output):\n",
    "      self.a_embeddings = to_np(output)\n",
    "      \n",
    "    self.model._modules.get('layer4').register_forward_hook(a_hook)\n",
    "\n",
    "  def forward(self, input):\n",
    "    return self.model(input)\n",
    "\n",
    "  def __repr__(self):\n",
    "    return \"Wrappper\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ImageFolder\n",
    "nft_dataset = ImageFolder(root=nft_images_root_folder, transform=preprocess)\n",
    "\n",
    "# Create a DataLoader to feed everything to the GPU\n",
    "nft_loader = torch.utils.data.DataLoader(nft_dataset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image names\n",
    "list_of_files = [a[0] for a in nft_loader.dataset.imgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save image names in a text file for further processing\n",
    "with open('imagelist.txt', 'w') as f:\n",
    "  f.write('\\n'.join(list_of_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = Lyaer4Extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "  for batch_idx, (data, target) in enumerate(tqdm(nft_loader)):\n",
    "    data = data.cuda() # Using CUDA\n",
    "    _ = extractor(data)\n",
    "    embeddings.append(extractor.a_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate everything to have a one large array\n",
    "embeddigns_np = concat(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing on the Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store on the disk\n",
    "np.save('Embeddings.npy', embeddigns_np)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep36",
   "language": "python",
   "name": "deep36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
